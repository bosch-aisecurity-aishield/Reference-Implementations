{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ff4e92",
   "metadata": {
    "id": "a2ff4e92"
   },
   "source": [
    "# Classification Model\n",
    "* File Name: Reference_implementation of BFSI \n",
    "* Date of creation(dd-mm-yyyy) : 27-01-2023\n",
    "* Author Name/Dept : AIShield\n",
    "* Organization : BGSW\n",
    "* Description : Source Code of reference implementation of AIShield API\n",
    "* Copyright : Copyright 2022 Bosch Global Software Technologies Private Limited. All Rights Reserved.\n",
    "\n",
    "### Metadata\n",
    "* Dataset: Banking Marketing Campagin\n",
    "* Size of dataset:41188, 18\n",
    "* Number of class : 2\n",
    "* Original Model: XGBOOST \n",
    "\n",
    "### Outcomes\n",
    "* Accuracy of model: 0.92\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715e737",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bosch-aisecurity-aishield/Reference-Implementations/blob/main/Product_Taskpair_wise/Tabular_Classification/extraction/Extraction_Reference_Implementation_BFSI.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c839be0",
   "metadata": {
    "id": "8c839be0",
    "outputId": "b676dae1-71c8-46f4-b87b-98eefe83b2cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription: commands to install all the packages, remove comments to install all the libraries\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: commands to install all the packages, remove comments to install all the libraries\n",
    "\"\"\"\n",
    "# !pip install xgboost==1.6.2\n",
    "# !pip install pandas==1.1.5\n",
    "# !pip install scikit-learn==1.0.2\n",
    "# !pip install numpy==1.22\n",
    "# !pip install pyminizip\n",
    "# !pip install requests==2.28.0\n",
    "# !pip install humanfriendly==9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c9ff6",
   "metadata": {
    "id": "4c6c9ff6"
   },
   "source": [
    "# 1.0 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1063adb",
   "metadata": {
    "id": "d1063adb"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Import libraries\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import shutil\n",
    "import requests\n",
    "import py_compile\n",
    "import pyminizip\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61778f3c",
   "metadata": {
    "id": "61778f3c"
   },
   "source": [
    "# 2.0 Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b367a0",
   "metadata": {
    "id": "25b367a0"
   },
   "source": [
    "#### Download dataset from the link https://archive.ics.uci.edu/dataset/222/bank+marketing\n",
    "1. then download the bank-additional.zip file and extract it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daeef26",
   "metadata": {},
   "source": [
    "##### Download bank-additional.zip dataset from the link https://archive.ics.uci.edu/dataset/222/bank+marketing and extract it. For this tutorial, file is already downloaded. If running in colab, uncomment the below cell to upload the downloaded zip file in Colab (folder finally needs to be present under 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79486f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To upload the downloaded zip file in Colab, please uncomment the below cell.\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "# import io\n",
    "\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# def extract_nested_zip(zip_file):\n",
    "#     # Look for nested zip files\n",
    "#     nested_zip_names = [name for name in zip_file.namelist() if name.endswith(\".zip\")]\n",
    "\n",
    "#     if not nested_zip_names:\n",
    "#         print(\"No nested zip files found.\")\n",
    "#         return\n",
    "\n",
    "#     for nested_zip_name in nested_zip_names:\n",
    "#         with zip_file.open(nested_zip_name) as nested_zip_file:\n",
    "#             with io.BytesIO(nested_zip_file.read()) as nested_buffer:\n",
    "#                 with zipfile.ZipFile(nested_buffer, 'r') as nested_zip:\n",
    "#                     # Extract the contents of the nested zip file\n",
    "#                     nested_zip.extractall()\n",
    "\n",
    "# for name, content in uploaded.items():\n",
    "#     with io.BytesIO(content) as buffer:\n",
    "#         with zipfile.ZipFile(buffer, 'r') as outer_zip:\n",
    "#             # Extract the contents of the outer zip file\n",
    "#             outer_zip.extractall()\n",
    "\n",
    "#             # Extract nested zip files recursively\n",
    "#             extract_nested_zip(outer_zip)\n",
    "\n",
    "# print(\"Extraction completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17101e50",
   "metadata": {
    "id": "17101e50"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Description : Loading the banking-marketing campaign dataset\n",
    "'''\n",
    "df = pd.read_csv('bank-additional/bank-additional-full.csv',delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de6f10",
   "metadata": {
    "id": "16de6f10",
    "outputId": "e17bd35f-7056-4caa-b3f6-8ab153980550"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd10c5b",
   "metadata": {
    "id": "dbd10c5b",
    "outputId": "edd46c70-cf7b-44ca-f70e-d8e3af3081b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9de604",
   "metadata": {
    "id": "db9de604"
   },
   "outputs": [],
   "source": [
    "df.replace(['basic.6y','basic.4y', 'basic.9y'], 'basic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829a0bc",
   "metadata": {
    "id": "7829a0bc"
   },
   "outputs": [],
   "source": [
    "columns = ['day_of_week','month']\n",
    "df.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e1bdb",
   "metadata": {
    "id": "413e1bdb"
   },
   "outputs": [],
   "source": [
    "'''Description : Label Encoding the Categorical Columns'''\n",
    "\n",
    "le =LabelEncoder()\n",
    "df.job = le.fit_transform(df.job)\n",
    "df.marital = le.fit_transform(df.marital)\n",
    "df.education = le.fit_transform(df.education)\n",
    "df.housing = le.fit_transform(df.housing)\n",
    "df.loan = le.fit_transform(df.loan)\n",
    "df.poutcome = le.fit_transform(df.poutcome)\n",
    "df.contact = le.fit_transform(df.contact)\n",
    "df.default = le.fit_transform(df.default)\n",
    "df.y = le.fit_transform(df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8af9b",
   "metadata": {
    "id": "f8e8af9b",
    "outputId": "f2c05e5b-6a62-490a-e67f-580a1c1ea12b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  duration  \\\n",
       "0   56    3        1          0        0        0     0        1       261   \n",
       "1   57    7        1          1        1        0     0        1       149   \n",
       "2   37    7        1          1        0        2     0        1       226   \n",
       "3   40    0        1          0        0        0     0        1       151   \n",
       "4   56    7        1          1        0        0     2        1       307   \n",
       "\n",
       "   campaign  pdays  previous  poutcome  emp.var.rate  cons.price.idx  \\\n",
       "0         1    999         0         1           1.1          93.994   \n",
       "1         1    999         0         1           1.1          93.994   \n",
       "2         1    999         0         1           1.1          93.994   \n",
       "3         1    999         0         1           1.1          93.994   \n",
       "4         1    999         0         1           1.1          93.994   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0          -36.4      4.857       5191.0  0  \n",
       "1          -36.4      4.857       5191.0  0  \n",
       "2          -36.4      4.857       5191.0  0  \n",
       "3          -36.4      4.857       5191.0  0  \n",
       "4          -36.4      4.857       5191.0  0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c8b51",
   "metadata": {
    "id": "a30c8b51"
   },
   "outputs": [],
   "source": [
    "output = 'y'\n",
    " \n",
    "X = df.loc[:, df.columns != output]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9103a3",
   "metadata": {
    "id": "9a9103a3"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Description : Splitting data for validation\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a67238",
   "metadata": {
    "id": "43a67238",
    "outputId": "2d1ebd9d-c82a-491b-c92d-6a5a942324f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train:  (30891, 18)\n",
      "shape of y_train: (30891,)\n",
      "shape of x_test: (10297, 18)\n",
      "shape of y_test: (10297,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Description : Check size of dataset\n",
    "'''\n",
    "print(\"shape of x_train: \",X_train.shape)\n",
    "print(\"shape of y_train: {}\".format(y_train.shape))\n",
    "print(f'shape of x_test: {X_test.shape}')\n",
    "print(f'shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4c5ef",
   "metadata": {
    "id": "71a4c5ef"
   },
   "source": [
    "# 3.0 Model Development and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddeefe0",
   "metadata": {
    "id": "2ddeefe0"
   },
   "outputs": [],
   "source": [
    "def make_directory(directory):\n",
    "    \"\"\"\n",
    "    create directory\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directorys : list containing the directorys path to create \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    for d in directory:\n",
    "        if os.path.isdir(d):\n",
    "            print(\"directory {} already exist\".format(d))\n",
    "        if os.path.isdir(d)==False:\n",
    "            os.mkdir(path=d)\n",
    "            print(\"directory {} created successfully\".format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94544919",
   "metadata": {
    "id": "94544919"
   },
   "outputs": [],
   "source": [
    "def delete_directory(directorys):\n",
    "    \"\"\"\n",
    "    delete directory \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directorys : list containing the directorys to deleate along with all the files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    if len(directorys)>=1:\n",
    "        for d in directorys:\n",
    "            if os.path.isdir(d):\n",
    "                try:\n",
    "                    if os.path.isfile(d):\n",
    "                        os.remove(path=d)\n",
    "                    else:\n",
    "                        shutil.rmtree(path=d)\n",
    "                        print(\"Removed: {}\".format(d))\n",
    "                except:\n",
    "                    print(\"Failed to removed: {}\".format(d))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8c157",
   "metadata": {
    "id": "b0e8c157"
   },
   "outputs": [],
   "source": [
    "def make_archive(base_name,root_dir,zip_format='zip'):\n",
    "    \"\"\"\n",
    "    created zip for given folder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_name : name of zip file\n",
    "    root_dir : directory to archive/zip\n",
    "    zip_format : zip or tar \n",
    "        DESCRIPTION. The default is 'zip'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    shutil.make_archive(base_name=base_name, format=zip_format, root_dir=root_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71484de8",
   "metadata": {
    "id": "71484de8"
   },
   "outputs": [],
   "source": [
    "\"Description : Create data, model and label folder\"\n",
    "data_path=os.path.join(os.getcwd(),\"data\")\n",
    "model_path=os.path.join(os.getcwd(),\"model\")\n",
    "minmax_path=os.path.join(os.getcwd(),\"minmax\")\n",
    "zip_path=os.path.join(os.getcwd(),\"zip\")\n",
    "pyc_model_path=os.path.join(os.getcwd(),\"pycmodel\")\n",
    "report_path = os.path.join(os.getcwd(), \"reports\")\n",
    "#deleting folder\n",
    "delete_directory(directorys=[data_path,model_path,minmax_path,zip_path,pyc_model_path,report_path])\n",
    "\n",
    "#creating folder\n",
    "make_directory([data_path,model_path,minmax_path,zip_path,pyc_model_path,report_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145cb11",
   "metadata": {
    "id": "7145cb11"
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    XG = XGBClassifier()\n",
    "    return XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c53e53",
   "metadata": {
    "id": "85c53e53",
    "outputId": "9c5aceac-eac3-4613-a363-7a484a0bceae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description : Create architecture of the model\n",
    "\"\"\"\n",
    "model=model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca8c8e",
   "metadata": {
    "id": "cbca8c8e",
    "outputId": "51ca0829-d326-42b7-9234-0aecfa74bd6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription: Trainig the model \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Trainig the model \n",
    "\"\"\"\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73aab17",
   "metadata": {
    "id": "a73aab17"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving the model under model directory\n",
    "\"\"\"\n",
    "modelname = \"xgboost_tc_mdl.pkl\"\n",
    "pickle.dump(model, open(model_path+\"/\"+modelname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb68e03",
   "metadata": {
    "id": "dbb68e03"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Get prediction on validation data\n",
    "\"\"\"\n",
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34554a",
   "metadata": {
    "id": "1d34554a",
    "outputId": "16c7e370-a35a-4e2e-e941-f92415bf76c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Decision Tree model is 0.9159949499854326\n",
      "F1 score of the Decision Tree model is 0.601932811780948\n",
      "Confusion Matrix \n",
      " [[8778  354]\n",
      " [ 511  654]]\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      9132\n",
      "           1       0.65      0.56      0.60      1165\n",
      "\n",
      "    accuracy                           0.92     10297\n",
      "   macro avg       0.80      0.76      0.78     10297\n",
      "weighted avg       0.91      0.92      0.91     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, pred)))\n",
    "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, pred)))\n",
    "print('Confusion Matrix \\n {}'.format(confusion_matrix(y_test, pred)))\n",
    "print('Classification Report \\n {}'.format(metrics.classification_report(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21105697",
   "metadata": {
    "id": "21105697"
   },
   "source": [
    "# 4.0 Prepare Data , Model and MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299f8a2",
   "metadata": {
    "id": "5299f8a2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Zip data\n",
    "\"\"\"\n",
    "df.to_csv(os.path.join(data_path,\"banking_final_dataset.csv\"),index=False)\n",
    "make_archive(base_name=os.path.join(zip_path,\"data\"),root_dir=data_path,zip_format='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625cdbb8",
   "metadata": {
    "id": "625cdbb8"
   },
   "outputs": [],
   "source": [
    "\"\"\"Prepare MinMax\"\"\"\n",
    "\n",
    "min_values = df.min().to_numpy()\n",
    "max_values = df.max().to_numpy()\n",
    "x= np.array([min_values,max_values])\n",
    "df_m = pd.DataFrame(x,columns=df.columns)\n",
    "df_m.to_csv(minmax_path+\"/minmax.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545fe49",
   "metadata": {
    "id": "6545fe49"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Zip Minmax\n",
    "\"\"\"\n",
    "make_archive(base_name=os.path.join(zip_path,\"minmax\"),root_dir=minmax_path,zip_format='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d096b44",
   "metadata": {
    "id": "7d096b44"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Create encrypted Model\n",
    "\"\"\"\n",
    "def create_model_pyc(model, model_framework,pyc_model_path):\n",
    "    \n",
    "    if model_framework.lower() == \"scikit-learn\":\n",
    "\n",
    "        python_code ='''\n",
    "#importing libraries\n",
    "import pickle\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "    class for base model\n",
    "\"\"\"\n",
    "#define class\n",
    "class BaseModel():\n",
    "    def __init__(self,model_path=\"\"):\n",
    "\n",
    "        \"\"\"\n",
    "        constructor for class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : TYPE, optional\n",
    "            DESCRIPTION. The default is (100,1).\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        \n",
    "    def load_protected_pickleModel(self,filename,password,picklemodelname):\n",
    "      \n",
    "\n",
    "        \"\"\"\n",
    "        model architecture\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : string\n",
    "            DESCRIPTION.zipped protected filename\n",
    "            \n",
    "        password : String\n",
    "            DESCRIPTION.zipped file password\n",
    "        \n",
    "        picklemodelname  :String\n",
    "            DESCRIPTION.pickle file name present in a ziiped protected\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        model : model\n",
    "            DESCRIPTION.\n",
    "\n",
    "        \"\"\"\n",
    "        filepath = os.path.join(self.model_path,filename)\n",
    "        #print(filepath)\n",
    "        #print(filename)\n",
    "        with zipfile.ZipFile(filepath, 'r') as file:\n",
    "            with file.open(picklemodelname,'r',pwd = bytes(password, 'utf-8')) as f:\n",
    "                pck = pickle.load(f)\n",
    "        return pck\n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "        \"\"\"\n",
    "        predict for given data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array \n",
    "            DESCRIPTION.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred : numpy array\n",
    "            DESCRIPTION.\n",
    "\n",
    "        \"\"\"\n",
    "        filename = \"modelencrypt.zip\"\n",
    "        password = \"987654321\"\n",
    "        picklemodelname = \"xgboost_tc_mdl.pkl\"\n",
    "        model = self.load_protected_pickleModel(filename=filename,password=password,picklemodelname=picklemodelname)\n",
    "        pred = model.predict(X)\n",
    "        return pred'''\n",
    "        # Writing to file\n",
    "        with open(\"base_model.py\", \"w\") as file:\n",
    "            # Writing data to a file\n",
    "            file.writelines(python_code)\n",
    "         \n",
    "        \"\"\"\n",
    "        Description: function to create .pyc file\n",
    "        \"\"\"\n",
    "        py_compile.compile(file=\"base_model.py\",cfile=pyc_model_path+'/base_model.pyc')\n",
    "        \n",
    "        \"\"\"\n",
    "        Description: function to create zipped password protected pickle model file\n",
    "        \"\"\"\n",
    "\n",
    "        def zip_model(input_path,output_path,password,com_lvl=5):\n",
    "            pyminizip.compress(input_path, None, output_path,\n",
    "                               password, com_lvl)\n",
    "            \n",
    "        zip_model(input_path =os.path.join(model_path,modelname),output_path = pyc_model_path+\"/modelencrypt.zip\" ,password = \"987654321\",com_lvl=5)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a69c28",
   "metadata": {
    "id": "d1a69c28"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Creating encrypted Model\n",
    "\"\"\"\n",
    "model_framework = \"scikit-learn\"\n",
    "model_encryption = 0 #0 for non encrypted file and 1 for encrypted (pyc) \n",
    "create_model_pyc(model,model_framework, pyc_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd15e7",
   "metadata": {
    "id": "09bd15e7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Zip model\n",
    "\"\"\"\n",
    " #0 if model is uploaded directly as a zip, 1 if model is encryted as .pyc and uploaded as a zip\n",
    "if os.path.isfile(os.path.join(zip_path,\"model.zip\")):\n",
    "    delete_directory(directorys=[os.path.join(zip_path,\"model.zip\")])\n",
    "if model_encryption:\n",
    "    make_archive(base_name=os.path.join(zip_path,\"bfsi_pyc_model\"),root_dir=pyc_model_path,zip_format='zip')\n",
    "else:\n",
    "    make_archive(base_name=os.path.join(zip_path,\"model\"),root_dir=model_path,zip_format='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e45bb4",
   "metadata": {
    "id": "f9e45bb4"
   },
   "source": [
    "# 5.0 AIShield API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd53fb",
   "metadata": {
    "id": "dddd53fb"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: AIShield API URL and subscription key\n",
    "\"\"\" \n",
    "baseurl = \"XXXXXXXXXXXXXXXXXXXXXXXXXXX\" # fill in API endpoint url from AIShield developer portal under API tab \n",
    "url = baseurl + \"/api/ais/v1.5\"\n",
    "headers={'Cache-Control': 'no-cache',\n",
    "'x-api-key': \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", # fill in subscription key from AIShield developer portal under My Dashboard tab\n",
    "'Org-Id' : \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"  # fill in Org_Id provided in welcome email\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b14bde",
   "metadata": {
    "id": "97b14bde",
    "outputId": "7be3f6dc-bfc4-4bec-ac23-e9990d3fced4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id:  38320ed1-8c31-42b4-8b74-c77cc3a10dce\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: call Model registration api to get unique model it and url to upload data, model and label\n",
    "\"\"\"\n",
    "model_registration_url = url + \"/model_registration/upload\"\n",
    "model_registration_payload = {\n",
    "    'task_type':\"TC\",\n",
    "    \"analysis_type\": \"MEA\"\n",
    "}\n",
    "new_request = requests.request(method=\"POST\", url=model_registration_url, headers=headers, json=model_registration_payload)\n",
    "new_request=json.loads(new_request.text)\n",
    "if 'data' in new_request.keys():\n",
    "    model_id = new_request[\"data\"]['model_id']\n",
    "    data_upload_url = new_request[\"data\"][\"urls\"]['data_upload_url']\n",
    "    label_upload_url = new_request[\"data\"][\"urls\"]['minmax_upload_url']\n",
    "    model_upload_url = new_request[\"data\"][\"urls\"]['model_upload_url']\n",
    "\n",
    "    print('model_id: ', model_id)\n",
    "else:\n",
    "    for k, v in new_request.items():\n",
    "        print(\"* {} : {}\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1d120",
   "metadata": {
    "id": "18e1d120"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Files path\n",
    "\"\"\"\n",
    "data_path=os.path.join(zip_path,'data.zip')  # full path of data zip\n",
    "label_path=os.path.join(zip_path,'minmax.zip') # full path of label zip\n",
    "# model_path=os.path.join(zip_path,'bfsi_pyc_model.zip') # uncomment if model_encryption = 1 (pyc)\n",
    "model_path=os.path.join(zip_path,'model.zip') # uncomment if model_encryption = 0 (unencrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf2810",
   "metadata": {
    "id": "8edf2810"
   },
   "outputs": [],
   "source": [
    "def upload_file(url, file_path):\n",
    "    \"\"\"\n",
    "    url: URL to upload\n",
    "    file_path: file to be uploaded\n",
    "    \"\"\"\n",
    "    new_request = requests.request(method=\"PUT\", url=url, data=open(file_path,'rb'))\n",
    "    status_cd = new_request.status_code\n",
    "    if status_cd == 200:\n",
    "        status = 'upload sucessful'\n",
    "    else:\n",
    "        status = 'upload failed'\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634f4ad",
   "metadata": {
    "id": "8634f4ad",
    "outputId": "18a35df4-2fc7-417a-fdbc-457c7151e136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_upload_status:  upload sucessful\n",
      "label_upload_status:  upload sucessful\n",
      "model_upload_status:  upload sucessful\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Hit AIShield File Upload API\n",
    "\"\"\"\n",
    "data_upload_status = upload_file(data_upload_url, data_path)\n",
    "print('data_upload_status: ', data_upload_status)\n",
    "label_upload_status = upload_file(label_upload_url, label_path)\n",
    "print('label_upload_status: ', label_upload_status)\n",
    "model_upload_status = upload_file(model_upload_url, model_path)\n",
    "print('model_upload_status: ', model_upload_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d9afde",
   "metadata": {
    "id": "f5d9afde"
   },
   "source": [
    "### 5.2 Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747fb75",
   "metadata": {
    "id": "a747fb75"
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "            \"use_model_api\":\"no\",\n",
    "            'input_dimensions': \"41188,18\",\n",
    "            \"number_of_classes\": 2,\n",
    "            \"number_of_attack_queries\": 50000,\n",
    "            \"vulnerability_threshold\": 0,\n",
    "            \"attack_type\": 'blackbox',\n",
    "            \"encryption_strategy\": 0,  # no encryption\n",
    "            \"normalize_data\": \"yes\",\n",
    "            \"defense_bestonly\": \"yes\",\n",
    "            \"is_category_columns\" : \"yes\",\n",
    "            \"categorical_columns_info\" : \"job,marital,education,default,housing,loan,contact,poutcome\",\n",
    "            \"model_api_details\" :\"na\",\n",
    "            \"model_framework\":\"scikit-learn\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1e4b1",
   "metadata": {
    "id": "b2e1e4b1",
    "outputId": "2573d276-ab38-4b41-edd0-1b0b42876d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* api_version : 1.5\n",
      "* job_id : XXXXXXXXXXXXXXXXXXXX\n",
      "* monitor_link : XXXXXXXXXXXXXXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Hit AIShield VulnerabilityReport api\n",
    "\"\"\"\n",
    "model_analysis_url = url + \"/model_analyse/\"+model_id\n",
    "if data_upload_status == \"upload sucessful\" and model_upload_status == \"upload sucessful\" and label_upload_status == \"upload sucessful\":\n",
    "    new_request = requests.request(method=\"POST\", url=model_analysis_url, json=payload,headers=headers)\n",
    "    new_request=json.loads(new_request.text)\n",
    "    for k, v in new_request.items():\n",
    "        print(\"* {} : {}\".format(k,v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ecd98b",
   "metadata": {
    "id": "52ecd98b",
    "outputId": "d6669fe4-331f-4750-b50f-da23956dc2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job id : XXXXXXXXXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Get job id from api response\n",
    "\"\"\"\n",
    "job_id=new_request['job_id']\n",
    "print(f\"Job id : {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63884e",
   "metadata": {
    "id": "5e63884e"
   },
   "outputs": [],
   "source": [
    "def monitor_api_progress(new_job_id):\n",
    "        job_status_url = url + \"/job_status_detailed?job_id=\" + new_job_id\n",
    "\n",
    "        # status dictionary\n",
    "        status_dictionary = {\n",
    "            'ModelExploration_Status': 'na',\n",
    "            'SanityCheck_Status': 'na',\n",
    "            'QueryGenerator_Status': 'na',\n",
    "            'VunerabilityEngine_Status': 'na',\n",
    "            'DefenseReport_Status': 'na',\n",
    "        }\n",
    "        counts = [0] * len(status_dictionary)\n",
    "        failed_api_hit_count = 0\n",
    "        while True:\n",
    "            time.sleep(2)\n",
    "            try:\n",
    "                job_status_response = requests.request(\"GET\", job_status_url, params={},\n",
    "                                                       headers=headers)\n",
    "\n",
    "                job_status_payload = json.loads(job_status_response.text)\n",
    "                failing_key = 'ModelExploration_Status'\n",
    "                for i, key in enumerate(status_dictionary.keys()):\n",
    "                    if status_dictionary[key] == 'na':\n",
    "                        if job_status_payload[key] == 'inprogress' and status_dictionary[key] == 'na':\n",
    "                            status_dictionary[key] = job_status_payload[key]\n",
    "                            print(str(key), \":\", status_dictionary[key])\n",
    "\n",
    "                        elif job_status_payload[key] == 'completed' or job_status_payload[key] == 'passed':\n",
    "                            status_dictionary[key] = job_status_payload[key]\n",
    "                            counts[i] += 1\n",
    "                            print(str(key), \":\", status_dictionary[key])\n",
    "\n",
    "                        if job_status_payload[key] == 'failed':\n",
    "                            failing_key = key\n",
    "                            status_dictionary[key] = job_status_payload[key]\n",
    "                            print(str(key), \":\", status_dictionary[key])\n",
    "\n",
    "                    elif job_status_payload[key] == 'completed' or job_status_payload[key] == 'passed':\n",
    "                        status_dictionary[key] = job_status_payload[key]\n",
    "                        if counts[i] < 1:\n",
    "                            print(str(key), \":\", status_dictionary[key])\n",
    "                        counts[i] += 1\n",
    "\n",
    "                    else:\n",
    "                        if job_status_payload[key] == 'failed':\n",
    "                            failing_key = key\n",
    "                            status_dictionary[key] = job_status_payload[key]\n",
    "                            print(str(key), \":\", status_dictionary[key])\n",
    "\n",
    "                if job_status_payload[failing_key] == 'failed':\n",
    "                    break\n",
    "\n",
    "                if status_dictionary['VunerabilityEngine_Status'] == 'passed' or status_dictionary[\n",
    "                    'VunerabilityEngine_Status'] == 'completed' and job_status_payload[\n",
    "                    'CurrentStatus'] == \"Defense generation is not triggered\":\n",
    "                    print(\"\\n Vulnerability score {} failed to cross vulnerability threshold of {}\".format(\n",
    "                        job_status_payload['VulnerabiltyScore'], payload['vulnerability_threshold']))\n",
    "                    break\n",
    "                if job_status_payload['DefenseReport_Status'] == 'completed':\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                failed_api_hit_count += 1\n",
    "                print(\"Error {}. trying {} ...\".format(str(e), failed_api_hit_count))\n",
    "                if failed_api_hit_count >= 3:\n",
    "                    break\n",
    "        return status_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416d363",
   "metadata": {
    "id": "6416d363",
    "outputId": "95c665da-ec4c-4640-8ae5-78ca4ae7f33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelExploration_Status : completed\n",
      "SanityCheck_Status : passed\n",
      "QueryGenerator_Status : completed\n",
      "VunerabilityEngine_Status : completed\n",
      "DefenseReport_Status : completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Continuos monitoring of jod progress\n",
    "\"\"\"\n",
    "status_dictionary = monitor_api_progress(new_job_id=job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c15e8",
   "metadata": {
    "id": "df7c15e8"
   },
   "outputs": [],
   "source": [
    "def download_artifact(job_id, report_type='Vulnerability', file_format=0):\n",
    "    \"\"\"\n",
    "    job_id: job_id  received after successful api call\n",
    "    report_type: report to be downloaded\n",
    "    file_format: change file_format to : 0- all report in zip \n",
    "                        1- report in .txt \n",
    "                        2- report in .pdf\n",
    "                        3- report in .json\n",
    "                        4- report in .xml\n",
    "    \"\"\"\n",
    "    report_url = url + \"/get_report?job_id=\" + str(\n",
    "        job_id) + \"&report_type=\" + report_type + \"&file_format=\" + str(file_format)\n",
    "\n",
    "    headers1=headers\n",
    "    headers1[\"content-type\"]= \"application/zip\"\n",
    "\n",
    "    response = requests.request(\"GET\", report_url, params={}, headers=headers1)\n",
    "\n",
    "    if file_format == 0 or \"Attack_samples\":\n",
    "        with open(os.path.join(report_path, report_type + \".zip\"), 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    elif file_format == 1:\n",
    "        with open(os.path.join(report_path, report_type + \".txt\"), 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    elif file_format == 2:\n",
    "        with open(os.path.join(report_path, report_type + \".pdf\"), 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    elif file_format == 3:\n",
    "        with open(os.path.join(report_path, report_type + \".json\"), 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    elif file_format == 4:\n",
    "        with open(os.path.join(report_path, report_type + \".xml\"), 'wb') as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a985ae",
   "metadata": {
    "id": "62a985ae"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: download generated artifact\n",
    "\"\"\"\n",
    "if status_dictionary[\"VunerabilityEngine_Status\"] == 'completed':\n",
    "    download_artifact(job_id=job_id, report_type='Vulnerability', file_format=0) \n",
    "    download_artifact(job_id=job_id, report_type='Attack_samples', file_format=0)\n",
    "\n",
    "if status_dictionary[\"DefenseReport_Status\"] == 'completed':\n",
    "    download_artifact(job_id=job_id, report_type='Defense', file_format=0)\n",
    "    download_artifact(job_id=job_id, report_type='Defense_artifact', file_format=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587a2e6",
   "metadata": {
    "id": "3587a2e6"
   },
   "outputs": [],
   "source": [
    "def zip_extractor(file, extract_path=None, delete_zip=False):\n",
    "    \"\"\"\n",
    "    extract zip file to the given path\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : path of zip file\n",
    "    extract_path : path to extract zip file, default considered parent directory\n",
    "    delete_zip: True, delete zip file after unzipping it\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    if extract_path is None:\n",
    "        extract_path = os.path.dirname(file)\n",
    "    print(\"Extracting : {}\".format(file))\n",
    "    zf = zipfile.ZipFile(file=file, mode='r')\n",
    "    zf.extractall(extract_path)\n",
    "    zf.close()\n",
    "    if delete_zip:\n",
    "        os.remove(file)\n",
    "        print(\"{} removed successfully.\".format(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbb078",
   "metadata": {
    "id": "c2cbb078",
    "outputId": "bafc6506-8186-4c18-a681-e19b64ac9dc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription: Extracting defense artifact\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Extracting defense artifact\n",
    "\"\"\"\n",
    "zip_extractor(file=os.path.join(report_path, 'Defense_artifact.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54333835",
   "metadata": {
    "id": "54333835",
    "outputId": "6ffee1aa-b96c-41a5-e4a5-f6f72af2f9a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription: Extracting attack sample\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Extracting attack sample\n",
    "\"\"\"\n",
    "zip_extractor(file=os.path.join(report_path, 'Attack_samples.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a7fa4",
   "metadata": {
    "id": "009a7fa4"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Load defense model\n",
    "\"\"\"\n",
    "defense_model_path = os.path.join(report_path, 'defense_model.pkl')\n",
    "defense_model = pickle.load(open(defense_model_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072945f7",
   "metadata": {
    "id": "072945f7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Use defense model\n",
    "\"\"\"\n",
    "from reports import predict\n",
    "defense = predict.AISDefenseModel(defense_model,model_framework=\"scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d53a78",
   "metadata": {
    "id": "52d53a78",
    "outputId": "140f4d99-7258-45c3-a3cb-705d1e644158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=1000,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "print(defense.defense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df91ce",
   "metadata": {
    "id": "35df91ce",
    "outputId": "673871ad-8495-44e7-839d-24f3b61499e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: ['not-attack' 'not-attack' 'not-attack' 'not-attack' 'not-attack']\n",
      "prob: [0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Pass Original sample data to get prediction\n",
    "\"\"\"\n",
    "label, prob = defense.predict(X_test[:5])\n",
    "print(\"label: {}\".format(label))\n",
    "print(\"prob: {}\".format(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9950cbf",
   "metadata": {
    "id": "c9950cbf"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description: Loading the attack data\n",
    "\"\"\"\n",
    "attack_sample = pd.read_csv('reports/attack_samples.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba2e6b",
   "metadata": {
    "id": "22ba2e6b",
    "outputId": "db63bfd9-48f2-48fe-8b16-122b35ad2460"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_label: ['attack' 'attack' 'attack' 'attack' 'attack']\n",
      "attack_prob: [1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: Pass attack sample data to get prediction\n",
    "\"\"\"\n",
    "attack_label, attack_prob= defense.predict(attack_sample[:5])\n",
    "print(\"attack_label: {}\".format(attack_label))\n",
    "print(\"attack_prob: {}\".format(attack_prob))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
